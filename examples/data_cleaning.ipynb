{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset used**\n",
    "- open_iof_20min_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data links\n",
    "data_url = {\n",
    "    'iof_data_1min_csv' : \"https://drive.google.com/uc?id=1_jYVXj7mt8Zzpjn8WGI111G-kWRTbfjU\",\n",
    "    'iof_data_1min_parq' : \"https://drive.google.com/uc?id=1j5SS136UzbSPu8TqG9RRUMi6-wWF9dzq\",\n",
    "    'mixingTank' :  \"https://drive.google.com/uc?id=1b5Qn5LIa6KAE03Tq4yRVdhTyUmZLxRjt\",\n",
    "    'moons' : \"https://drive.google.com/uc?id=1a9zTkPEpuHGj6LzGzuLe-JSLg_4GJef4\",\n",
    "    'open_iof_20min' : \"https://drive.google.com/uc?id=15lkhdBfWnjlpgpEx4T2XcRApKr-dmBb0\",\n",
    "    'open_iof_cleaned' : \"https://drive.google.com/uc?id=1WVbJvYsGy-iKlsW4WaDZrKy_NhK2tJLW\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd                 \n",
    "import matplotlib.pyplot as plt     \n",
    "import numpy as np                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas display format: two decimals\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest data\n",
    "fname = data_url['open_iof_20min']\n",
    "indexColumn = 'date' \n",
    "dateColumns = ['date']\n",
    "df = pd.read_csv(fname, index_col=indexColumn, parse_dates=dateColumns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at current column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "## Rename columns (variables) for easier interpretation\n",
    "# Create a dictionory which contains the old names and new names\n",
    "# Format: dictionary = {'old_name_variable_1': 'new_name_variable_1', 'old_name_variable_2': 'new_name_variable_2'}\n",
    "old_comp_names = ['plant.feed.iron.comp', \n",
    "                'plant.feed.silica.comp',\n",
    "                'plant.filters.product.iron.comp', \n",
    "                'plant.filters.product.silica.comp']\n",
    "new_comp_names = ['d feed iron %',\n",
    "                'd feed silica %',\n",
    "                'y product iron %',\n",
    "                'y product silica %']\n",
    "\n",
    "old_sump_names = ['plant.flotation.sump01.starch.flow',\n",
    "                'plant.flotation.sump01.amina.flow',\n",
    "                'plant.flotation.sump01.discharge.flow',\n",
    "                'plant.flotation.sump01.discharge.ph',\n",
    "                'plant.flotation.sump01.discharge.density']\n",
    "\n",
    "new_sump_names = ['u starch m3/h',\n",
    "                'u amina m3/h',\n",
    "                'd feed m3/h',\n",
    "                'd feed ph',\n",
    "                'd feed SG']\n",
    "\n",
    "old_air_flow_names = [name for name in df.columns if 'air.flow' in name]\n",
    "new_air_flow_names = [name.replace('plant.flotation.bank01.column','x C') + ' Nm3/h' for name in old_air_flow_names]\n",
    "\n",
    "old_depth_names = [name for name in df.columns if 'froth' in name]\n",
    "new_depth_names = [name.replace('plant.flotation.bank01.column','x C') + ' mm' for name in old_depth_names]\n",
    "\n",
    "old_names = old_comp_names+old_sump_names+old_air_flow_names+old_depth_names\n",
    "new_names = new_comp_names+new_sump_names+new_air_flow_names+new_depth_names\n",
    "\n",
    "nameChangeDictionary = dict(zip(old_names,new_names))\n",
    "nameChangeDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in the data frame according to the specified dictionary\n",
    "df.rename(columns=nameChangeDictionary, inplace=True)\n",
    "# Look at the new column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers: .loc()\n",
    "The slicing/indexing function with assignment can be used to deal with outliers:\n",
    "\n",
    "Identify outlier rows and replace outliers with missing values (`np.nan`). Missing values can then be handled as discussed further below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection: Knowledge-based (visual highlighting)\n",
    "df.plot(subplots=True,figsize=(10,50),marker='.')\n",
    "# Domain-knowledge prompts: \n",
    "# air flow < 200 Nm3/h\n",
    "# froth depth < 200 mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection:\n",
    "# Assigning missing values to rows specified as containing outliers\n",
    "outlierRowsAirFlow01 = df['x C01.air.flow Nm3/h'] < 200\n",
    "df.loc[outlierRowsAirFlow01,'x C01.air.flow Nm3/h'] = np.nan\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection\n",
    "df['x C01.air.flow Nm3/h'].plot(marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers from more columns\n",
    "for name in new_air_flow_names:\n",
    "    df.loc[df[name]<200,name] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Practice Point\n",
    "Remove outliers from 'x C04.froth.depth mm' where the values are above 600. Display the basic statistics of the data frame or plot the froth depth data to check if your outlier removal worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values: .fillna()\n",
    "Missing values (represented by `np.nan`) can be replaced by fixed values, e.g., the mean or median of the variable in question. The method `.fillna()` can be used to replace `np.nan` with a fixed value.\n",
    "\n",
    "`.ffill()` and `.bfill()` can also be used for forward filling or backward filling, instead of a fixed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values: Filling with fixed value\n",
    "df['d feed iron % (mean replacement)'] = df['d feed iron %'].fillna(df['d feed iron %'].mean())\n",
    "df['d feed iron % (mean replacement)'].plot(marker='.',figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values: Forward fill\n",
    "df['d feed iron % (forward fill)'] = df['d feed iron %'].ffill()\n",
    "df['d feed iron % (forward fill)'].plot(marker='.',figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values: Backward fill\n",
    "df['d feed iron % (backward fill)'] = df['d feed iron %'].bfill()\n",
    "df['d feed iron % (backward fill)'].plot(marker='.',figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values: Interpolation (linear, time reference)\n",
    "df['d feed iron % (interpolated)'] = df['d feed iron %'].interpolate(method='time')\n",
    "df['d feed iron % (interpolated)'].plot(marker='.',figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Practice Point\n",
    "Use different methods to fill 'd feed silica %' missing values. Show the result of the data cleaning by plotting the filled variable in a time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values: Final replacement decision\n",
    "df['d feed iron %'] = df['d feed iron %'].bfill()\n",
    "df['d feed silica %'] = df['d feed silica %'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop demonstraton variables from data frame\n",
    "variables_to_delete = ['d feed iron % (mean replacement)',\n",
    "    'd feed iron % (forward fill)',\n",
    "    'd feed iron % (backward fill)',\n",
    "    'd feed iron % (interpolated)']\n",
    "df.drop(labels=variables_to_delete,axis=1,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values: Understanding the size of the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing value occurences in a variable\n",
    "print(\"Missing data percent:\")\n",
    "for vname in df.columns:\n",
    "    missingpercent = 100*df[vname].isnull().sum()/df.shape[0]\n",
    "    if missingpercent > 0:\n",
    "        print(f\"{missingpercent:4.1f} % missing in {vname}\")\n",
    "        # Unpacking {missingpercent:4.1f} \n",
    "        # -- missingpercent = number to display\n",
    "        # -- : = indicates that formatting of number will follow\n",
    "        # -- 4 = width in characters allocated for display of number (can be longer)\n",
    "        # -- . = indicates decimal point\n",
    "        # -- 1 = indicates number of digits after decimal point\n",
    "        # -- f = indicates variable type, a floating point number in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise removal: .rolling()\n",
    "Rolling window calculations can be done on data frames. For a specific row, a window (i.e., fixed number of preceding rows) is considered, and a calculation done on values on that window. The result is stored in that row, and then the window calculation is repeated for the next row.\n",
    "\n",
    "The sample time is specified in special string notation, with format `[number][unit]`, e.g., `'10S'`. Units include:\n",
    "- 'd': day frequency\n",
    "- 'h': hour frequency\n",
    "- 'min': minute frequency\n",
    "- 's': second frequency\n",
    "\n",
    "For more units, see [this link](https://pandas.pydata.org/docs/user_guide/timeseries.html#timeseries-offset-aliases).\n",
    "\n",
    "When `.rolling()` is applied, the sampling frequency of the data frame stays the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal: Filtering\n",
    "# Visualize noisy variable\n",
    "df['u starch m3/h'].plot(marker='.',ls='none',figsize=(12,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal: Filtering\n",
    "# Rolling average\n",
    "df['u starch m3/h (filtered)'] = df['u starch m3/h'].rolling('1d').mean()\n",
    "# Visualize smoothed variable\n",
    "df['u starch m3/h (filtered)'].plot(marker='.',ls='none',figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Practice Point\n",
    "Play around with the size of the rolling window (e.g., 1 hour, 1 day, 1 week) and the type of summary statistic (e.g., mean, median, maximum, sum) to determine a good tradeoff of rolling window size as well as summary statistic. Visualize your result in each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down/upsampling: Resampling\n",
    "For time series data, the `.resample()` method can be used to change the sample time of the data. For example, if the data was original captured at 20 second intervals, but a rolled up sample time of 1 hour is of interest, `.resample()` can be used to aggregate the data to 1 hour intervals.\n",
    "\n",
    "**Downsampling** involves going from a high sampling frequency (short time between samples) to a low sampling frequency (long time between samples). This implies that some aggregate statistic needs to be calculated to transform the many samples of the high frequency data to the fewer samples of the low frequency result. Operations like `.mean()` or `.median()` can be used.\n",
    "\n",
    "When `.resample()` is applied, the sampling frequency of the data frame changes. \n",
    "\n",
    "**Upsampling** involves going from a low sampling frequency to a high sampling frequency, typically when joining more than one dataframe. This will result in missing values (`NaN`), since it is unknown what happened between observed values. Missing value replacement can be used to estimate (\"guess\") what happed at a higher frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling: Median approach\n",
    "# (downsampled to hourly values)\n",
    "dfIOFHourly = df.resample('1h').median()\n",
    "dfIOFHourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling: Median approach\n",
    "dfIOFHourly.plot(subplots=True,marker='.',figsize=(10,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling: Combining two data frames and upsampling low frequency data\n",
    "# Create example data frames with certain time range and sampling frequency\n",
    "# (note: this would typically be done by importing from csv/xlsx)\n",
    "# Low frequency measurement\n",
    "date_range1 = pd.date_range(start='2025-05-01', periods=30, freq='h')\n",
    "df1 = pd.DataFrame({\n",
    "    'timestamp': date_range1,\n",
    "    'Product quality': 0.2*np.random.randn(30),\n",
    "})\n",
    "df1.set_index('timestamp', inplace=True)\n",
    "df1.plot(marker='.')\n",
    "# High frequency measurement\n",
    "date_range2 = pd.date_range(start='2025-05-01', periods=30*60, freq='min')\n",
    "df2 = pd.DataFrame({\n",
    "    'timestamp': date_range2,\n",
    "    'Temperature': 70+5*np.random.randn(30*60),\n",
    "})\n",
    "df2.set_index('timestamp', inplace=True)\n",
    "df2.plot(marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two dataframes\n",
    "df_combined = pd.concat([df1,df2],axis=1)\n",
    "df_combined.plot(subplots=True,marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsampling (backfill)\n",
    "df_combined.bfill().plot(subplots=True,marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "df_combined.resample('1h').median().plot(subplots=True,marker='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values: .dropna()\n",
    "List-wise deletion of missing values (i.e., removing rows with any missing values in it) can be done with the `.dropna()` method. To ensure that the data frame is modified, the argument `inplace=True` is included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing values: List-wise deletion\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean dataset\n",
    "df.to_csv('../data/open_data_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rbm_dape",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
